{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "from typing import Literal, TypedDict\n",
    "from thefuzz import fuzz\n",
    "from pandas import Series, DataFrame\n",
    "from constructor import DataframeConstructor\n",
    "\n",
    "from interfaces import InnerPdData, LangNameData, OriginalCiaLanguageData\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from FuzzySearcher import FuzzySearcher, FuzzySearcherData\n",
    "\n",
    "\n",
    "from typing import Any, TypedDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_constructor = DataframeConstructor()\n",
    "\n",
    "\n",
    "def init_pd_settings():\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "init_pd_settings()\n",
    "\n",
    "result = df_constructor.create_base_df(create_data_for_base_df())\n",
    "base_df = result[\"base_df\"]\n",
    "df = result[\"df\"]\n",
    "\n",
    "lang_name_df = df_constructor.create_rest_api_language_name_dataframe(getLangFiles())\n",
    "\n",
    "new_cia_language_df = df_constructor.create_new_cia_language_dataframe(create_data_for_new_cia_df())\n",
    "original_wiki_language_df = DataFrame(get_wiki_files())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\"to_replace\": [r\"\\bthe\\b\", r\"\\bof\\b\", r\"\\bThe\\b\", \",\"], \"value\": \"\", \"regex\": True}\n",
    "\n",
    "# clean data\n",
    "df[\"wiki_country_id\"] = base_df[\"wiki_country\"]\n",
    "df[\"cia_country_id\"] = base_df[\"cia_country\"]\n",
    "df[\"cia_country\"] = df['cia_country'].replace(**default_args)\n",
    "df[\"wiki_country\"] = df['wiki_country'].replace(**default_args)\n",
    "\n",
    "lang_name_df[\"common\"] = lang_name_df[\"common\"].replace(**default_args)\n",
    "lang_name_df[\"official\"] = lang_name_df[\"official\"].replace(**default_args)\n",
    "\n",
    "new_cia_language_df[\"country\"] = new_cia_language_df[\"country\"].replace(**default_args)\n",
    "original_wiki_language_df[\"Country/Region\"] = original_wiki_language_df[\"Country/Region\"].replace(**default_args)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join cia and wiki data\n",
    "\n",
    "- Filter the data by base ratio strategy first then apply token set ratio strategy\n",
    "- Join the data afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-evaluate ratio algorithm\n",
    "\n",
    "df[\"similarity\"] = df.apply(lambda row: FuzzySearcher(\"ratio\").run(row[\"cia_country\"], row[\"wiki_country\"]), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given how languages have many unique words, token set ratio is unlikely to yield a false positive. All countries that pass are most likely equivalent.\n",
    "\n",
    "\n",
    "def filter_token_set_less_than_100(row: pd.Series):\n",
    "    ratio = FuzzySearcher(\"token_set_ratio\").run(row[\"cia_country\"], row[\"wiki_country\"])\n",
    "    \n",
    "    row[\"similarity\"] = ratio\n",
    "    return row\n",
    "\n",
    "df = df.apply(filter_token_set_less_than_100, axis=\"columns\")\n",
    "df.sort_values(by=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add exceptions after manual review\n",
    "\n",
    "exceptions = [117,187,213,182,35]\n",
    "\n",
    "df[\"is_exception\"] = df.apply(lambda row: row.name in exceptions, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define policy that determines whether or not a country from the cia table has a match in the wiki table\n",
    "df['has_wiki_country_equivalent'] = df.apply(lambda row: (row[\"is_exception\"] == True) | (row[\"similarity\"] == 100), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# join previous result with lang table\n",
    "\n",
    "- Same general strategy as first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize dependencies\n",
    "def get_max_country(row):\n",
    "    max_score = max(row['common_score'], row['common_score_token_set'], row['official_score'], row['official_score_token_set'])\n",
    "    if max_score == row['common_score'] or max_score == row['common_score_token_set']:\n",
    "        return row['common_country']\n",
    "    else:\n",
    "        return row['official_country']\n",
    "\n",
    "\n",
    "data_list:list[InnerPdData] = []\n",
    "\n",
    "\n",
    "# apply same strategy from before, where base ratio strategy is run first before using token ratio strategy (could be refactored into reusable function)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    \n",
    "    country:str = row[\"cia_country\"]\n",
    "    country_id = row[\"cia_country_id\"]\n",
    "    \n",
    "    for _, lang_row in lang_name_df.iterrows():\n",
    "        data:InnerPdData = {\n",
    "            \"common_score\":FuzzySearcher(\"ratio\").run(country, lang_row[\"common\"]),\n",
    "            \"common_country\":lang_row[\"common\"],\n",
    "            \"common_score_token_set\":FuzzySearcher(\"token_set_ratio\").run(country, lang_row[\"common\"]),\n",
    "            \"compared_country\":country,\n",
    "            \"official_score\":FuzzySearcher(\"ratio\").run(country, lang_row[\"official\"]),\n",
    "            \"official_score_token_set\":FuzzySearcher(\"token_set_ratio\").run(country, lang_row[\"official\"]),\n",
    "            \"official_country\":lang_row[\"official\"],\n",
    "            \"compared_country_id\":country_id\n",
    "        }\n",
    "        \n",
    "        data_list.append(data)\n",
    "\n",
    "\n",
    "fuzzy_score_df = DataFrame(data_list)\n",
    "\n",
    "# Label table with maximums derived from fuzzy search scores\n",
    "fuzzy_score_df['max_country'] = fuzzy_score_df.apply(get_max_country, axis=1)\n",
    "fuzzy_score_df['max_score'] = fuzzy_score_df[['common_score', 'common_score_token_set', 'official_score', 'official_score_token_set']].max(axis=1)\n",
    "fuzzy_score_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate view\n",
    "top_df = fuzzy_score_df.groupby(\"compared_country_id\").apply(lambda x: x.nlargest(1, \"max_score\")).reset_index(drop=True)\n",
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View of countries that did not have a perfect match\n",
    "\n",
    "top_df[top_df[\"max_score\"] != 100].sort_values(by=\"max_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define policy for what constitutes a match\n",
    "\n",
    "top_df[\"is_match\"] = top_df.apply(lambda row: row[\"max_score\"] >= 75, axis=1)\n",
    "top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join results\n",
    "\n",
    "\n",
    "joined_df = pd.merge(top_df, df, left_on=\"compared_country_id\", right_on=\"cia_country_id\", how=\"outer\")\n",
    "joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking keys are still the same since your code modified the keys and i had to recreate the modifications\n",
    "\n",
    "def apply_fuzzy_search(row: Series):\n",
    "    \n",
    "    \n",
    "    \n",
    "    results = FuzzySearcher(\"ratio\").run_against_multiple(row[\"country\"], joined_df[\"cia_country\"].tolist())\n",
    "    \n",
    "    row[\"top_similarity\"] = results.top_result.similarity\n",
    "    row[\"top_country\"] = results.top_result.right\n",
    "    \n",
    "    \n",
    "    \n",
    "    return row\n",
    "    \n",
    "\n",
    "new_cia_language_df = new_cia_language_df.apply(apply_fuzzy_search, axis=1)\n",
    "new_cia_language_df.sort_values(by=\"top_similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double checking keys are still the same since your code modified the keys and i had to recreate the transforms in order to join them\n",
    "\n",
    "def apply_fuzzy_search(row: Series):\n",
    "    \n",
    "    \n",
    "    \n",
    "    results = FuzzySearcher(\"ratio\").run_against_multiple(row.iloc[1], joined_df[\"wiki_country\"].tolist())\n",
    "    \n",
    "    row[\"top_similarity\"] = results.top_result.similarity\n",
    "    row[\"top_country\"] = results.top_result.right\n",
    "    \n",
    "    \n",
    "    \n",
    "    return row\n",
    "    \n",
    "\n",
    "original_wiki_language_df = original_wiki_language_df.apply(apply_fuzzy_search, axis=1)\n",
    "original_wiki_language_df.sort_values(by=\"top_similarity\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
